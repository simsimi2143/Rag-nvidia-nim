# Sistema RAG con NVIDIA AI Endpoints :rocket:

Sistema de RecuperaciÃ³n Aumentada por GeneraciÃ³n (RAG) para documentos PDF, utilizando modelos avanzados de NVIDIA y tÃ©cnicas de procesamiento de lenguaje natural.

## VisiÃ³n General

Este proyecto implementa un pipeline completo para:
- Procesar documentos PDF (extracciÃ³n, divisiÃ³n de texto)
- Generar embeddings con modelos de NVIDIA
- Realizar bÃºsquedas semÃ¡nticas usando FAISS
- Responder preguntas mediante el modelo Llama 3.3 de NVIDIA

**Casos de uso**: InvestigaciÃ³n acadÃ©mica, anÃ¡lisis de documentos legales, asistentes inteligentes para PDFs.

## Requisitos Previos

- Python 3.9+
- NVIDIA API Key (registrada en [NVIDIA NGC](https://catalog.ngc.nvidia.com/))
- LibrerÃ­as listadas en `requirements.txt`

## InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone [repo-url]
cd [repo-name]
```

2. Instalar dependencias:
```bash
pip install -r requirements.txt
```

3. Configurar API key (opciÃ³n preferida: usar variables de entorno):
```bash
export NVIDIA_API_KEY="tu_api_key_aquÃ­"
```

## Uso BÃ¡sico

1. Colocar tu PDF en la carpeta `/data`
2. Ejecutar el sistema:
```python
python rag_pipeline.py --pdf_path /data/tu_documento.pdf
```

3. Interactuar con el asistente:
```
ðŸŒŸ Asistente RAG - Basado en tu PDF ðŸ“„

ðŸ¤” Tu pregunta: Â¿CuÃ¡l es el objetivo principal del documento?
```

## Estructura del CÃ³digo

```
/project
â”œâ”€â”€ rag_pipeline.py          # Pipeline principal
â”œâ”€â”€ config.py                # Configuraciones
â”œâ”€â”€ utils/                   # Utilidades
â”‚   â”œâ”€â”€ text_processing.py   # Procesamiento de texto
â”‚   â””â”€â”€ error_handling.py    # Manejo de errores
â”œâ”€â”€ data/                    # Documentos PDF
â””â”€â”€ README.md                # Este archivo
```

## ConfiguraciÃ³n Avanzada

ParÃ¡metros personalizables en `config.py`:
```python
CHUNK_SIZE = 200              # TamaÃ±o de fragmentos de texto
MODEL_NAME = "llama-3.3-nemotron-super-49b-v1"
SEARCH_KWARGS = {"k": 2}      # Resultados por consulta
MAX_TOKENS = 400              # LÃ­mite para embeddings
```

## Ejemplo Completo

Procesamiento de un trabajo acadÃ©mico:
```python
from pipeline import create_rag_system

rag = create_rag_system(
    pdf_path="Trabajo_de_Titulo_FINAL.pdf",
    chunk_size=150,           # MÃ¡s pequeÃ±o para espaÃ±ol
    model="nvidia/llama-3.3"
)

response = rag.query("Â¿QuÃ© metodologÃ­a usÃ³ el autor?")
print(response["result"])
```

## Licencia

MIT License - Ver archivo [LICENSE](LICENSE) para detalles.

## Notas TÃ©cnicas

:warning: **Requisitos de Hardware**:  
Se recomienda GPU NVIDIA para embeddings grandes. Para CPU:
- Reducir `chunk_size` a 100-150
- Usar `NVIDIAEmbeddings(..., model="small")`

:tools: **Soporte**:  
Problemas conocidos y soluciones en [ISSUES.md](ISSUES.md)
```

### CaracterÃ­sticas clave de este README:
1. **Estructura modular**: SeparaciÃ³n clara de componentes
2. **Instrucciones detalladas**: Desde instalaciÃ³n hasta uso avanzado
3. **Ejemplos prÃ¡cticos**: CÃ³digo listo para copiar-pegar
4. **Notas tÃ©cnicas**: Optimizaciones para diferentes hardware
5. **Enfoque en espaÃ±ol**: ParÃ¡metros ajustados para texto en espaÃ±ol

Â¿Te gustarÃ­a que agregue alguna secciÃ³n adicional? Por ejemplo:
- ðŸ“Š Benchmarks de rendimiento
- ðŸ§© Ejemplo de archivo requirements.txt
- ðŸŽ¥ Demo con GIF animado
